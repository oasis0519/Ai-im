{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 980M (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('vgg16_gender2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = np.load('summ.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def model_predict(model, img, mean, im_height = 224, im_width = 224, rounded = False):\n",
    "    image_final = np.zeros((1,224,224,3))\n",
    "    img = cv2.resize(img, (im_width, im_height))\n",
    "    img = img - mean\n",
    "    image_final[0,:,:,:] = img\n",
    "    image_final = np.swapaxes(image_final, 1, 3)\n",
    "    image_final = np.swapaxes(image_final, 2, 3)\n",
    "    \n",
    "    prediction = model.predict(image_final)\n",
    "    \n",
    "    if rounded:\n",
    "        if prediction > 0.7:\n",
    "            return \"MALE\"\n",
    "        else:\n",
    "            return \"FEMALE\"\n",
    "    \n",
    "    \n",
    "    return str(prediction)\n",
    "\n",
    "\n",
    "def recognize_person():\n",
    "    gender = \"\"\n",
    "    face_cascade = cv2.CascadeClassifier('../Capture-Face-master/face_detection_xml/face_cascade_classifier.xml')\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    face_detected = False\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = video_capture.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            image = frame[max(0, y - 40): min(frame.shape[0], y+h + 40), max(0, x - 40):min(frame.shape[1], x+w + 40)]\n",
    "            cv2.imwrite('face.png', image)\n",
    "            gender = model_predict(model, image, mean)\n",
    "            face_detected = True\n",
    "        if face_detected:\n",
    "            cv2.putText(image, gender, (image.shape[1]/5, image.shape[0]/5), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n",
    "            cv2.imshow(\"Prediction\", image)\n",
    "            raw_input(\"Enter To continue\")\n",
    "            face_detected = False\n",
    "        cv2.imshow('img', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    #When everything is done, release the capture\n",
    "    video_capture.release()\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "recognize_person()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
